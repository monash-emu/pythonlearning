{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import numpy as jnp, random, lax, jit, grad, scipy as jsp, value_and_grad\n",
    "from jax import Array\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_x(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical gradient of x is always 1.0\n",
    "# (ie the gradient of the function is x)\n",
    "\n",
    "grad(ret_x)(6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gradient is the same in this function\n",
    "\n",
    "def add_one(x):\n",
    "    return x + 1.0\n",
    "\n",
    "grad(add_one)(5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply 2 values\n",
    "\n",
    "def just_multiply(x, y):\n",
    "    return x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient of both variables (args 0,1)\n",
    "# The result is the input arguments swapped;\n",
    "# Since the function is purely multiplicative, the rate at which\n",
    "# change in x produces change in the output is the value of y, and vice versa\n",
    "\n",
    "grad(just_multiply, [0,1])(1.5,4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(mean, sd, k, N) -> Array:\n",
    "    \"\"\"Random gaussian walk\n",
    "\n",
    "    Args:\n",
    "        mean: Gaussian mean\n",
    "        sd: Gaussian sd\n",
    "        k: Jax PRNGKey\n",
    "        N: Number of timesteps\n",
    "\n",
    "    Returns:\n",
    "        Array of random walk values\n",
    "    \"\"\"\n",
    "    return jnp.cumsum(random.normal(k,(N,)) * sd + mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example random walk.  Try changing the seed value of the key\n",
    "\n",
    "k = random.PRNGKey(0)\n",
    "pd.Series(random_walk(0.0,1.0, k,128)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value and gradient of our random walk function\n",
    "# We evaluate this on the last value of the random walk (gradients can only be computed over a scalar output)\n",
    "# Note that gradient of the mean (first argument) is always the length of the sequence\n",
    "# Since the random walk is just a cumulative sum of N steps, this is exactly as expected\n",
    "# When the mean is 0.0, the gradient of the standard deviation is equal to the value of\n",
    "# the output; ie changes in the output are produced entirely by this parameter\n",
    "# These values of course change with different random keys (different random walks)\n",
    "# When the mean is not 0.0, the output is a combination of the 2 inputs (with gradients reflecting this)\n",
    "\n",
    "# Thus we can think of the gradient of a stochastic function as being deterministic for a given value of k\n",
    "\n",
    "k = random.PRNGKey(0)\n",
    "N = 128\n",
    "\n",
    "mean = 0.0\n",
    "sd = 1.0\n",
    "\n",
    "value_and_grad(lambda mean, sd, k, N: random_walk(mean,sd,k,N)[-1],[0,1])(mean, sd, k, N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfilt312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
